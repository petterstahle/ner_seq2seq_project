{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/exotic_ninja/Documents/Uni/Master/Cours/sem4/METL/ner_seq2seq_project\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.neural_baseline import *\n",
    "from src.utils.conlleval import *\n",
    "\n",
    "print(f'Current working directory: {os.getcwd()}')\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "\n",
    "# notebook will reload external python modules;\n",
    "%autoreload 2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(dataset, ner_model, mapping):\n",
    "    all_true_tag_ids, all_predicted_tag_ids = [], []\n",
    "    \n",
    "    for x, y in dataset:\n",
    "        output = ner_model.predict(x, verbose=0)  # set verbose to 0\n",
    "        predictions = np.argmax(output, axis=-1)\n",
    "        predictions = np.reshape(predictions, [-1])\n",
    "\n",
    "        true_tag_ids = np.reshape(y, [-1])\n",
    "\n",
    "        mask = (true_tag_ids > 0) & (predictions > 0)\n",
    "        true_tag_ids = true_tag_ids[mask]\n",
    "        predicted_tag_ids = predictions[mask]\n",
    "\n",
    "        all_true_tag_ids.append(true_tag_ids)\n",
    "        all_predicted_tag_ids.append(predicted_tag_ids)\n",
    "\n",
    "    all_true_tag_ids = np.concatenate(all_true_tag_ids)\n",
    "    all_predicted_tag_ids = np.concatenate(all_predicted_tag_ids)\n",
    "\n",
    "    predicted_tags = [mapping[tag] for tag in all_predicted_tag_ids]\n",
    "    real_tags = [mapping[tag] for tag in all_true_tag_ids]\n",
    "    \n",
    "    res = evaluate(real_tags, predicted_tags, verbose = True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline n°1: Neural Network Implementation with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data and preparing vocabulary of size 20000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 9.57k/9.57k [00:00<00:00, 8.14MB/s]\n",
      "Downloading metadata: 100%|██████████| 3.73k/3.73k [00:00<00:00, 4.71MB/s]\n",
      "Downloading readme: 100%|██████████| 12.3k/12.3k [00:00<00:00, 6.10MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset conll2003/conll2003 to /home/exotic_ninja/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 983k/983k [00:00<00:00, 5.45MB/s]\n",
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conll2003 downloaded and prepared to /home/exotic_ninja/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 115.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing datasets...\n",
      "creating model...\n",
      "\n",
      "training model...\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 15:44:10.611578: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-05 15:44:10.611976: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64\n",
      "\t [[{{node Placeholder/_5}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439/439 [==============================] - 17s 31ms/step - loss: 0.6093\n",
      "Epoch 2/10\n",
      "439/439 [==============================] - 12s 28ms/step - loss: 0.2482\n",
      "Epoch 3/10\n",
      "439/439 [==============================] - 14s 31ms/step - loss: 0.1492\n",
      "Epoch 4/10\n",
      "439/439 [==============================] - 13s 29ms/step - loss: 0.1161\n",
      "Epoch 5/10\n",
      "439/439 [==============================] - 13s 30ms/step - loss: 0.0955\n",
      "Epoch 6/10\n",
      "439/439 [==============================] - 13s 29ms/step - loss: 0.0778\n",
      "Epoch 7/10\n",
      "439/439 [==============================] - 13s 30ms/step - loss: 0.0667\n",
      "Epoch 8/10\n",
      "439/439 [==============================] - 13s 29ms/step - loss: 0.0586\n",
      "Epoch 9/10\n",
      "439/439 [==============================] - 13s 29ms/step - loss: 0.0493\n",
      "Epoch 10/10\n",
      "439/439 [==============================] - 13s 30ms/step - loss: 0.0424\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "sample_text = \"eu rejects german call to boycott british lamb\"\n",
    "\n",
    "\n",
    "print(f\"processing data and preparing vocabulary of size {vocab_size}...\")    \n",
    "conll_data = load_and_prepare_data()\n",
    "\n",
    "mapping = make_tag_lookup_table()\n",
    "\n",
    "# vocab_size = 20000\n",
    "vocabulary = get_vocabulary(conll_data, vocab_size)\n",
    "\n",
    "print(f\"preparing datasets...\")\n",
    "lookup_layer = keras.layers.StringLookup(vocabulary=vocabulary)\n",
    "\n",
    "# batch_size = 32\n",
    "train_dataset, val_dataset = prepare_datasets(vocabulary, batch_size)\n",
    "\n",
    "num_tags = len(mapping)\n",
    "\n",
    "print(f\"creating model...\\n\")\n",
    "ner_model = create_model(num_tags, vocab_size)\n",
    "\n",
    "print(f\"training model...\\n\")\n",
    "compile_and_fit(ner_model, train_dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 41) (32, 41)\n"
     ]
    }
   ],
   "source": [
    "for x, y in val_dataset:\n",
    "    print(x.shape,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: eu rejects german call to boycott british lamb\n",
      "Predicted tags:\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O']\n",
      "\n",
      "calculating metrics...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 15:47:16.352309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-05 15:47:16.352948: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51362 tokens with 5942 phrases; found: 5795 phrases; correct: 4140.\n",
      "accuracy:  66.53%; (non-O)\n",
      "accuracy:  93.44%; precision:  71.44%; recall:  69.67%; FB1:  70.55\n",
      "              LOC: precision:  82.58%; recall:  81.06%; FB1:  81.81  1803\n",
      "             MISC: precision:  71.35%; recall:  68.33%; FB1:  69.81  883\n",
      "              ORG: precision:  65.24%; recall:  62.71%; FB1:  63.95  1289\n",
      "              PER: precision:  64.84%; recall:  64.06%; FB1:  64.45  1820\n",
      "\n",
      "\n",
      "precision: \t71.44\n",
      "   recall: \t69.67\n",
      "       f1: \t70.55\n"
     ]
    }
   ],
   "source": [
    "print('Sample text:', sample_text)\n",
    "print('Predicted tags:')\n",
    "print(predict_sample(ner_model, sample_text, mapping, lookup_layer))\n",
    "\n",
    "print(f\"\\ncalculating metrics...\\n\")\n",
    "res = calculate_metrics(val_dataset, ner_model, mapping)\n",
    "\n",
    "# res is a tuple of (precision, recall, f1), print it out beautifully\n",
    "print(\"\\n\")\n",
    "print(f\"precision: \\t{res[0]:.2f}\")\n",
    "print(f\"   recall: \\t{res[1]:.2f}\")\n",
    "print(f\"       f1: \\t{res[2]:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline n°2: CRF Implementation with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from src.crf_baseline import * \n",
    "from IPython.display import display\n",
    "\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "\n",
    "# notebook will reload external python modules;\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EU', 'NNP', 'B-NP', 'B-ORG'],\n",
       " ['rejects', 'VBZ', 'B-VP', 'O'],\n",
       " ['German', 'JJ', 'B-NP', 'B-MISC'],\n",
       " ['call', 'NN', 'I-NP', 'O'],\n",
       " ['to', 'TO', 'B-VP', 'O'],\n",
       " ['boycott', 'VB', 'I-VP', 'O'],\n",
       " ['British', 'JJ', 'B-NP', 'B-MISC'],\n",
       " ['lamb', 'NN', 'I-NP', 'O'],\n",
       " ['.', '.', 'O', 'O']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_raw_input(filename):\n",
    "    \"\"\"Read a train/test file and return the contents as a list of list of lists. \n",
    "    \n",
    "    The innermost list is a record of 4 items, one per word.\n",
    "    The middle-level list contains all the records in one sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    all_items = []\n",
    "\n",
    "    with open(filename) as fh:\n",
    "        current_item = []\n",
    "        all_items.append(current_item)\n",
    "\n",
    "        for line in fh:\n",
    "            tags = line.strip().split()\n",
    "            if len(tags) == 0 or tags[0] == '-DOCSTART-':\n",
    "                continue\n",
    "            current_item.append(tags)\n",
    "            if tags[0] == '.' and tags[1] == '.':\n",
    "                current_item = []\n",
    "                all_items.append(current_item)\n",
    "                \n",
    "    return all_items\n",
    "\n",
    "train_sents = read_raw_input('./data/CoNLL-2003_train.txt')\n",
    "test_sents = read_raw_input('./data/CoNLL-2003_test.txt')\n",
    "\n",
    "display(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>parse</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_seq_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boycott</td>\n",
       "      <td>VB</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lamb</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  pos parse     ner\n",
       "word_seq_num                            \n",
       "0                  EU  NNP  B-NP   B-ORG\n",
       "1             rejects  VBZ  B-VP       O\n",
       "2              German   JJ  B-NP  B-MISC\n",
       "3                call   NN  I-NP       O\n",
       "4                  to   TO  B-VP       O\n",
       "5             boycott   VB  I-VP       O\n",
       "6             British   JJ  B-NP  B-MISC\n",
       "7                lamb   NN  I-NP       O\n",
       "8                   .    .     O       O"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents = all_sentences(train_sents)\n",
    "test_sents  = all_sentences(test_sents)\n",
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7375/7375 [05:54<00:00, 20.80it/s]\n",
      "100%|██████████| 1627/1627 [01:22<00:00, 19.71it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = get_feature_values(train_sents)\n",
    "X_test = get_feature_values(test_sents)\n",
    "y_train, y_test = get_labels(train_sents), get_labels(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 69.1 ms, total: 1min 11s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=200,\n",
    "    verbose=False,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "display(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flat f1 score: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.870     0.839     0.854      1668\n",
      "       I-LOC      0.801     0.720     0.758       257\n",
      "      B-MISC      0.800     0.748     0.773       702\n",
      "      I-MISC      0.628     0.657     0.643       216\n",
      "       B-ORG      0.802     0.723     0.761      1661\n",
      "       I-ORG      0.655     0.734     0.692       835\n",
      "       B-PER      0.829     0.853     0.841      1617\n",
      "       I-PER      0.867     0.947     0.905      1156\n",
      "\n",
      "   micro avg      0.809     0.806     0.808      8112\n",
      "   macro avg      0.782     0.778     0.778      8112\n",
      "weighted avg      0.811     0.806     0.807      8112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "f1_score = metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)\n",
    "print(f\" flat f1 score: {f1_score:.2f}\")\n",
    "\n",
    "report = calculate_metrics_crf(y_test, y_pred, labels)\n",
    "print(f\"{report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
